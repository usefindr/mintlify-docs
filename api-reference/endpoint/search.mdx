---
title: 'Hybrid Search'
openapi: 'POST /search/retrieve'
---

Perform a hybrid search across your tenant's knowledge base using both semantic and keyword matching.

<Note>
**Default Sub-Tenant Behavior**: If you don't specify a `sub_tenant_id`, the search will be performed within the default sub-tenant created when your tenant was set up. This searches across organization-wide documents.
</Note>

## Search Modes

The Hybrid Search endpoint combines multiple search strategies to provide the most relevant results:

### Semantic Search
- **Purpose**: Finds content based on meaning and context, not just exact keywords
- **Best for**: Conceptual queries, finding related content, understanding intent
- **Example**: Searching for "machine learning" will also find content about "AI", "neural networks", "deep learning"

### Keyword Search  
- **Purpose**: Finds content containing specific terms or phrases
- **Best for**: Exact term matching, technical specifications, proper nouns
- **Example**: Searching for "TensorFlow 2.0" will find documents mentioning this specific version

### Hybrid Approach
- **Purpose**: Combines semantic understanding with keyword precision
- **Best for**: Most use cases where you want both relevance and accuracy
- **Example**: "Python data analysis libraries" finds both semantic matches (pandas, numpy) and exact keyword matches

## Search Parameters

### Alpha Parameter
Controls the balance between semantic and keyword search:

- **`0.0`** - Pure keyword search only
  - Best for: Exact term matching, technical specifications
  - Use when: You need precise keyword matches
  
- **`1.0`** - Pure semantic search only  
  - Best for: Conceptual queries, finding related content
  - Use when: You want to discover related concepts
  
- **`0.8`** - Default balanced approach (recommended)
  - Best for: Most general use cases
  - Provides optimal balance of precision and recall
  
- **`"auto"`** - Intelligent auto-selection
  - Cortex analyzes your query and chooses the optimal alpha
  - Best for: When you're unsure which approach to use

### Recency Bias
Controls how much recent content is prioritized:

- **`0.0`** - No recency bias (default)
- **`0.1-0.5`** - Light to moderate recency preference
- **`0.6-1.0`** - Strong recency preference
- **Best for**: News, documentation updates, time-sensitive information

### Max Chunks
Controls the number of results returned:
- **Range**: 1-1001 chunks
- **Default**: System limit
- **Recommendation**: Start with 10-20 for most use cases

## Search Optimization Tips

### For Better Precision
- Use **lower alpha values** (0.2-0.4) for exact term matching
- Include **specific terminology** in your queries
- Set **higher max_chunks** to get more comprehensive results

### For Better Recall
- Use **higher alpha values** (0.6-0.8) for broader semantic matching
- Try **synonyms and related terms** in your queries
- Use **conceptual language** rather than specific terms
- Enable **recency bias** for time-sensitive content

### For Complex Queries
- Use **"auto" alpha** to let Cortex optimize automatically
- Combine **specific terms with conceptual language**
- Adjust **recency bias** based on content type
- Experiment with **different alpha values** to find optimal results

## Sample Request

```bash
curl --location --request POST 'https://api.usecortex.ai/search/retrieve' \
  --header 'Authorization: Bearer {API_KEY}' \
  --header 'accept: application/json' \
  --header 'Content-Type: application/json' \
  --data '{
    "query": "{SEARCH_QUERY}",
    "tenant_id": "{TENANT_ID}",
    "sub_tenant_id": "{SUB_TENANT_ID}",
    "max_chunks": {MAX_CHUNKS},
    "alpha": "{ALPHA}",
    "recency_bias": {RECENCY_BIAS}
  }'
```

### Response
Returns an array of relevant content chunks from your indexed sources based on the search query.

```json
[
  {
    "chunk_uuid": "CortexDoc37e854b429784b148d4fc910812bdc581753761779_20_v1",
    "source_id": "CortexDoc37e854b429784b148d4fc910812bdc581753761779",
    "source_title": "IEEE Transactions LaTeX Templates.pdf",
    "chunk_content": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 12 Fig. 10: Comparison of models with 4bit precision on Medical QA dataset...",
    "source_url": "ToayuCogoBdxZVoZQ1ft8ZoRzCO2/Hello/Hello/local_source/CortexDoc37e854b429784b148d4fc910812bdc581753761779",
    "source_upload_time": "1753761802.079415",
    "source_collection": [],
    "source_type": "file",
    "layout": "{\"coordinates\": {\"x\": 48.96399688720703, \"y\": 26.49277114868164, \"width\": 514.0717697143555, \"height\": 721.1119651794434}, \"page\": 12}",
    "version": "v1",
    "source_last_updated_time": "",
    "relevancy_score": 0.8363813161849976,
    "rerank_score": null
  },
  {
    "chunk_uuid": "CortexDoc04d73ba38fd54325800a74ec17aed9041753761993_4_v1",
    "source_id": "CortexDoc04d73ba38fd54325800a74ec17aed9041753761993",
    "source_title": "IEEE Transactions LaTeX Templates.pdf",
    "chunk_content": "III. METHODOLOGY Our proposed framework integrates federated learning (FL) with blockchain technology to fine-tune Large Language Mod-",
    "source_url": "ToayuCogoBdxZVoZQ1ft8ZoRzCO2/Hello/Hello/local_source/CortexDoc04d73ba38fd54325800a74ec17aed9041753761993",
    "source_upload_time": "1753762013.1677928",
    "source_collection": [],
    "source_type": "file",
    "layout": "{\"coordinates\": {\"x\": 311.9779968261719, \"y\": 712.3123168945312, \"width\": 251.05746459960938, \"height\": 35.72357177734375}, \"page\": 2}",
    "version": "v1",
    "source_last_updated_time": "",
    "relevancy_score": 0.800000011920929,
    "rerank_score": null
  }
]
```

> **Note:** This endpoint returns hybrid search results without AI-generated answers. For conversational Q&A with AI-generated responses, use the `/search/qna` endpoint instead.

### Alpha Parameter
The `alpha` parameter controls the balance between semantic and keyword search:
- `0.0` = keyword search only
- `1.0` = semantic search only  
- `0.8` = default balanced approach
- `"auto"` = Cortex intelligently decides the optimal alpha value based on the query