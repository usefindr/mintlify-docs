---
title: 'Search Embeddings'
openapi: 'POST /embeddings/search-raw-embeddings'
---

import { TableOfContents } from '/snippets/table-of-contents.jsx'
import TryIt from '/snippets/try-it.mdx'

<Panel>
  <TableOfContents />
</Panel>
<TryIt />
### Examples

<Tabs>
  <Tab title="API Request">
    ```bash expandable
    curl -X 'POST' \
  'https://api.usecortex.ai/embeddings/search-raw-embeddings' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "tenant_id": "string",
  "sub_tenant_id": "string",
  "query_embedding": [
    0
  ],
  "limit": 10,
  "filter_expr": "string",
  "output_fields": [
    "string"
  ]
}'
      ```
  </Tab>
  <Tab title="TypeScript">
    ```ts
    const results = await client.embeddings.search({
      tenant_id: "tenant_1234",
      sub_tenant_id: "sub_tenant_4567",
      embeddings: [
        0.123413, 0.655367, 0.987654, 0.123456, 0.789012
      ],
      max_chunks: 10
    });
    ```
  </Tab>
  <Tab title="Python (Sync)">
    ```python
    # Async usage is similar, just use async_client and await
    results = client.embeddings.search(
        tenant_id="tenant_1234",
        sub_tenant_id="sub_tenant_4567",
        embeddings=[
            0.123413, 0.655367, 0.987654, 0.123456, 0.789012
        ],
        max_chunks=10
    )
    ```
  </Tab>
</Tabs>


Search for similar content using vector embeddings by comparing your input embedding against the vector database to find the most similar content chunks.

## Vector Search Concepts

### What are Embeddings?
Embeddings are high-dimensional vector representations of text that capture semantic meaning:
- **Semantic Understanding**: Similar concepts have similar vector representations
- **Mathematical Distance**: Content similarity is measured by vector distance
- **Language Agnostic**: Works across different languages and formats
- **Context Preservation**: Maintains meaning and relationships between concepts

### How Vector Search Works
1. **Input Processing**: Your embedding vector is compared against all stored embeddings
2. **Similarity Calculation**: Cosine similarity or other distance metrics are computed
3. **Ranking**: Results are ranked by similarity score (higher = more similar)
4. **Retrieval**: Most similar chunks are returned with their similarity scores

### Embedding Dimensions
- **Standard Dimensions**: Most embeddings use 384, 512, 768, or 1536 dimensions
- **Quality vs Speed**: Higher dimensions = better quality, slower search
- **Compatibility**: Ensure your embedding model matches Cortex's expected format

## Search Parameters

### Max Chunks
Controls the number of results returned:
- **Range**: 1-200 chunks
- **Default**: 10 chunks
- **Recommendation**: 
  - Start with 10-20 for most use cases
  - Use 50-100 for comprehensive searches
  - Use 1-5 for precise, top results only

### Embedding Format
- **Type**: Single embedding vector (1D array of numeric values)
- **Values**: Floating-point numbers (typically between -1 and 1)
- **Length**: Must match the embedding model's dimension size
- **Example**: `[0.1, -0.2, 0.3, 0.4, -0.5, ...]`

## Use Cases

### Semantic Similarity Search
- **Content Discovery**: Find documents similar to a reference document
- **Recommendation Systems**: Suggest related content based on user interests
- **Duplicate Detection**: Identify similar or duplicate content
- **Content Clustering**: Group related documents together

### Cross-Language Search
- **Multilingual Content**: Find similar content across different languages
- **Translation Support**: Search for content in one language using another
- **Global Knowledge**: Access information regardless of original language

### Advanced Retrieval
- **Conceptual Search**: Find content based on meaning, not exact keywords
- **Context-Aware Search**: Retrieve content that matches conceptual context
- **Fuzzy Matching**: Find content even with different wording or phrasing

## Best Practices

### Embedding Quality
- **Use High-Quality Models**: Choose well-trained embedding models (OpenAI, Cohere, etc.)
- **Consistent Models**: Use the same embedding model for both indexing and searching
- **Preprocessing**: Clean and normalize text before generating embeddings
- **Batch Processing**: Generate embeddings in batches for better performance

### Search Optimization
- **Appropriate Max Chunks**: Start with 10-20, adjust based on your needs
- **Similarity Thresholds**: Set minimum similarity scores to filter low-quality matches
- **Multiple Queries**: Try different embedding representations of the same concept
- **Hybrid Approaches**: Combine vector search with keyword search for better results

### Performance Considerations
- **Vector Size**: Larger vectors provide better quality but slower search
- **Index Size**: More indexed content = longer search times
- **Batch Requests**: Process multiple embeddings simultaneously when possible
- **Caching**: Cache frequently used embeddings to improve response times

## Common Patterns

### Document Similarity
```json
{
  "embeddings": [0.1, 0.2, 0.3, ...],
  "max_chunks": 20
}
```
Use when you want to find documents similar to a reference document.

### Concept Search
```json
{
  "embeddings": [0.4, -0.1, 0.8, ...],
  "max_chunks": 10
}
```
Use when searching for content related to a specific concept or topic.

### Recommendation Engine
```json
{
  "embeddings": [0.2, 0.5, -0.3, ...],
  "max_chunks": 50
}
```
Use when building recommendation systems that need many similar items.


## Sample Response

```json
{
  "chunk_ids": [
    "CortexEmbeddings123_0",    
    "CortexEmbeddings456_0",
    "CortexEmbeddings456_1",
    "CortexEmbeddings123_2",   
    "CortexEmbeddings123_8"
  ],
  "scores": [
    0.95,
    0.89,
    0.87,
    0.82,
    0.78
  ]
}
```

## Error Responses

All endpoints return consistent error responses following the standard format. For detailed error information, see our [Error Responses](/api-reference/error-responses) documentation.

